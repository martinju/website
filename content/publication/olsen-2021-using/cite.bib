@article{olsen2021using,
 abstract = {Shapley values are today extensively used as a model-agnostic explanation framework to explain complex predictive machine learning models. Shapley values have desirable theoretical properties and a sound mathematical foundation. Precise Shapley value estimates for dependent data rely on accurate modeling of the dependencies between all feature combinations. In this paper, we use a variational autoencoder with arbitrary conditioning (VAEAC) to model all feature dependencies simultaneously. We demonstrate through comprehensive simulation studies that VAEAC outperforms the state-of-the-art methods for a wide range of settings for both continuous and mixed dependent features. Finally, we apply VAEAC to the Abalone data set from the UCI Machine Learning Repository.},
 author = {Olsen, Lars Henry Berge and Glad, Ingrid Kristine and Jullum, Martin and Aas, Kjersti},
 doi = {https://doi.org/10.48550/arXiv.2111.13507},
 journal = {arXiv preprint arXiv:2111.13507},
 title = {Using Shapley Values and Variational Autoencoders to Explain Predictive Models with Dependent Mixed Features},
 year = {2021}
}

